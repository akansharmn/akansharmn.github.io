[{"categories":null,"contents":"Provides required dependencies and additional utilities to simplify and codify the process of building, testing and delivering Atlassian plugins all the way to the live marketplace. Executes integration/AUT level tests against all stated compatible versions for the productUploads generated artifact to Atlassian marketplaceProvides corresponding metadata indicating version, release notes, and compatibility\n","permalink":"https://akansharmn.github.io/projects/creations/azure-integration-services/","tags":["Microsoft Azure","Azure Biztalk Services","C#",".Net","REST APIs","AngularJS","Azure Active Directory","Encryption","Azure Key Vault","OData"],"title":"Azure Integration Services to provide EAI and B2B transaction capabilities"},{"categories":null,"contents":"Project Description This project maintains a web diary of user\u0026rsquo;s online web activities. Currently only online videos watched are in in scope. It allows a user to tag a video, store information or notes along with it. The user when laters visits that video page, he will be able to view all these informations. There are two parts to this project - A browser extension to help a user view all the information he stored while browsing videos and a backedn API to support it. This repository conatins a Restful Web API implemented in ASP.Net backed up by SQLite databse to store all the information.Following are the key features of this project -\n A centralized place to view all the web contents and information associated with it stored by the user. The information is stored offline and can be browsed anytime. These contents can be organized by placing them into different playlists. User can search videos with tags.  ","permalink":"https://akansharmn.github.io/projects/contributions/deploy-triggers/","tags":[".Net Core 2.0","OAuth 2.0","REST APIs","ReactJs","Swagger","C#","Chrome Extension"],"title":"Web Diary"},{"categories":null,"contents":"This talk looked at Liberty Mutual’s transformation to Continuous Integration, Continuous Delivery, and DevOps. For a large, heavily regulated industry, this task can not only be daunting, but viewed by many as impossible. Often, organizations try to reduce the friction through micro-fixes, but Eddie’s team asked how to change the culture to reduce the friction and concluded with the following final points:\n Don’t mandate DevOps. Give employees the chance to master their discipline with examples to set and follow. Favor deep end-to-end accomplishments over broad but incremental steps forward. Focus on taking the right teams far before encouraging broad adoption. Centralize the platforms and tools that your teams shouldn’t be thinking about. Provide foundational services/commodities and let teams stay on purpose. Incorporate contributions from everyone; don’t stifle autonomy. Stay open to new ways of working. Challenge security policies, but respect intentions. Find new ways to enforce concerns without abandoning precaution.    ","permalink":"https://akansharmn.github.io/publications/alldaydevops/","tags":["DevOps","Continuous Integration","Continuous Delivery","CI/CD pipelines","agile","Culture"],"title":"Organically DevOps: Building Quality and Security into the Software Supply Chain at Liberty Mutual"},{"categories":null,"contents":"  This work aims to maximize the lifetime of wireless sensor networks by grouping the sensor nodes into sets and activating the sets successively.By lifetime is meant the total time for which the sensor nodes can monitor the whole target area or all the target objects. Two different cases have been dealt with- one when the transmission and reception range of sensors can be adjusted and the other in which the range of transmission and reception is fixed.Three different algorithmic paradigms are used- Greedy heuristic, Genetic Algorithm and Particle Swarm Optimization The goal of the research is to propose an improved greedy heuristic and a new metaheuristic Particle Swarm Optimization (PSO) algorithm to increase the lifetime the sensor network by organizing the sensors into a maximal number of set covers that are activated successively. Two heuristics that efficiently compute the sets, using exact approximation algorithm greedy heuristic and meta-heuristic algorithms such as genetic algorithm and Particle Swarm Optimization have been designed.  ","permalink":"https://akansharmn.github.io/projects/creations/wsn/","tags":["Greedy Algorithm","Genetic Algorithm","Particle Swarm Optimization Algorithm","Matlab"],"title":"Final year thesis: Solving Target Coverage Problem in Wireess Sensor Networks Using Iterative Heuristic Algorithms"},{"categories":null,"contents":" Worked in a team to design and develop a distributed tracing mechanism for tracing Microsoft’s financial transactions flowing through multiple sub-systems  Enhanced the design to support tracing of batched transactions which can further split into multiple discrete transactions and multiple batched transactions and so on such that each final discrete transaction can be traced individually.  Developed a service to track the failed transactions and trace it back to its previous hop.  Developed a tool to onboard new clients (existing Lines Of Business with financial transactions) onto the tracking system and streamlined the onboarding process.  Implemented additional key features of the tracing system including correlation of transaction with acknowledgements at various stages and associating arbitrary contextual information at each hop of the transaction.  A UI powered by a REST API provided stakeholders to query the progress of each individual transactions. Worked on the API part to implement the search functionality based on various properties of transactions.  ","permalink":"https://akansharmn.github.io/projects/creations/distributed-tracing/","tags":["Microsoft Azure",".Net","C#","Javascript","Biztalk","Rest API","Cosmos Db","powershell","REST APIs","EventHub","Azure Functions","OAuth","AngularJS","Azure Search Service"],"title":"Distributed tracing of transactions for an existing financial transaction processing pipeline"},{"categories":null,"contents":" This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml\n[outputs] home = [\u0026quot;HTML\u0026quot;, \u0026quot;JSON\u0026quot;]  Searching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category\n... \u0026quot;contents\u0026quot;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026quot;tags\u0026quot;:{{ .Params.tags | jsonify }}{{end}}, \u0026quot;categories\u0026quot; : {{ .Params.categories | jsonify }}, ...  Edit fuse.js options to Search static/js/search.js\nkeys: [ \u0026quot;title\u0026quot;, \u0026quot;contents\u0026quot;, \u0026quot;tags\u0026quot;, \u0026quot;categories\u0026quot; ]  ","permalink":"https://akansharmn.github.io/search/","tags":null,"title":"Search Results"}]